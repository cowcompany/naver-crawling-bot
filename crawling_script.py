import os
import requests
import csv
import datetime
import re

from google.colab import drive
drive.mount('/content/drive')

# ğŸ“‚ GitHub Actions í™˜ê²½ì—ì„œ ì €ì¥í•  í´ë”
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ğŸ“Œ í¬ë¡¤ë§ ë‚ ì§œ ì¶”ê°€ (YYYY-MM-DD í˜•ì‹)
today_date = datetime.datetime.now().strftime("%Y-%m-%d")

def crawl_lease_properties(page=1):
    """ ì „ì„¸ ë§¤ë¬¼ì„ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜ """
    url = "https://new.land.naver.com/api/articles/complex/107024"
    params = {
        "realEstateType": "APT:PRE:ABYG:JGC",
        "tradeType": "B1",  # ì „ì„¸
        "tag": "::::::::",
        "rentPriceMin": "0",
        "rentPriceMax": "900000000",
        "priceMin": "0",
        "priceMax": "900000000",
        "areaMin": "0",
        "areaMax": "900000000",
        "oldBuildYears": "",
        "recentlyBuildYears": "",
        "minHouseHoldCount": "",
        "maxHouseHoldCount": "",
        "showArticle": "false",
        "sameAddressGroup": "false",
        "minMaintenanceCost": "",
        "maxMaintenanceCost": "",
        "priceType": "RETAIL",
        "directions": "",
        "page": page,
        "complexNo": "107024",
        "buildingNos": "",
        "areaNos": "",
        "type": "list",
        "order": "rank"
    }

    cookies = {
        "NAC": "7OkBBcg0CXTf",
        "NNB": "VNWULNT7WWJGO",
        "nid_inf": "37537044",
        "NID_AUT": "rvd2DEVgotRe2lvOC6e6gF/MWxjIBoWSs/sRbrwX7ET9yLggY0njNhGcuqz5EgvN",
        "NID_JKL": "iTfl2S7lzH/EWgTBPsv1VKkH092eASi/AR9qBOQMQK0=",
    }

    headers = {
        "accept": "*/*",
        "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3Mzk1NzAyNzMsImV4cCI6MTczOTU4MTA3M30.89ygvJtcP_W9uZY_2sXji-IKkrkUKuSsfFbBxYZ9FpU",
        "referer": "https://new.land.naver.com/complexes/107024?ms=37.5617871,127.1826662,17&a=APT:PRE:ABYG:JGC&e=RETAIL",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "same-origin",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36",
    }

    response = requests.get(url, params=params, cookies=cookies, headers=headers)

    # âœ… ì‘ë‹µ ë°ì´í„° í™•ì¸ (ë””ë²„ê¹…ìš©)
    print(f"í˜ì´ì§€ {page} ì‘ë‹µ ìƒíƒœ ì½”ë“œ:", response.status_code)

    if response.status_code == 200:
        data = response.json()
        print(f"í˜ì´ì§€ {page} ë°ì´í„° ê°œìˆ˜:", len(data.get("articleList", [])))  # âœ… ì‹¤ì œ ë°ì´í„° ê°œìˆ˜ í™•ì¸
        return data
    else:
        print("HTTP ì˜¤ë¥˜:", response.status_code)
        return None

# ğŸ“Œ ì „ì„¸ ê°€ê²©ì„ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_price_to_number(price_str):
    """
    '5ì–µ 8,000' â†’ 580000000
    '6ì–µ' â†’ 600000000
    '3ì–µ 5,000' â†’ 350000000
    """
    if not price_str:
        return 0

    price_str = price_str.replace(",", "")  # ì‰¼í‘œ ì œê±°
    match = re.match(r"(\d+)ì–µ(?:\s*(\d+))?", price_str)

    if match:
        billion = int(match.group(1)) * 100000000  # '5ì–µ' â†’ 500000000
        million = int(match.group(2)) * 10000 if match.group(2) else 0  # '8,000' â†’ 80000000
        return billion + million
    return 0

def save_to_csv(article_list, filename):
    """ ì „ì„¸ ë§¤ë¬¼ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ """
    fieldnames = [
        "ë§¤ë¬¼ë²ˆí˜¸", "ë§¤ë¬¼ëª…", "ìœ í˜•", "ê±°ë˜ìœ í˜•", "ì „ì„¸ê°€", "ì „ì„¸ê°€(ìˆ«ì)",
        "ì „ìš©ë©´ì ", "ê³µê¸‰ë©´ì ", "ë°©í–¥", "ì¸µìˆ˜", "date"  # ğŸ”¹ "íŠ¹ì§•"ê³¼ "íƒœê·¸" ì œê±°
    ]

    with open(filename, mode="w", newline="", encoding="utf-8-sig") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for article in article_list:
            price_str = article.get("dealOrWarrantPrc", "")
            price_num = convert_price_to_number(price_str)  # ğŸ”¹ ê°€ê²© ë³€í™˜ ì ìš©

            writer.writerow({
                "ë§¤ë¬¼ë²ˆí˜¸": article.get("articleNo", ""),  # ë§¤ë¬¼ ê³ ìœ ë²ˆí˜¸
                "ë§¤ë¬¼ëª…": article.get("articleName", ""),  # ë§¤ë¬¼ëª…
                "ìœ í˜•": article.get("realEstateTypeName", ""),  # ì•„íŒŒíŠ¸, ì˜¤í”¼ìŠ¤í…” ë“±
                "ê±°ë˜ìœ í˜•": article.get("tradeTypeName", ""),  # ë§¤ë§¤, ì „ì„¸, ì›”ì„¸
                "ì „ì„¸ê°€": price_str,  # ğŸ”¹ ì›ë˜ ë¬¸ì ê·¸ëŒ€ë¡œ ì €ì¥
                "ì „ì„¸ê°€(ìˆ«ì)": price_num,  # ğŸ”¹ ë³€í™˜ëœ ìˆ«ìë¡œ ì €ì¥
                "ì „ìš©ë©´ì ": article.get("area1", ""),  # ì „ìš©ë©´ì 
                "ê³µê¸‰ë©´ì ": article.get("area2", ""),  # ê³µê¸‰ë©´ì 
                "ë°©í–¥": article.get("direction", ""),  # ë‚¨í–¥, ë™í–¥ ë“±
                "ì¸µìˆ˜": article.get("floorInfo", ""),  # ì €/ì¤‘/ê³  ì¸µ ì •ë³´
                "date": today_date  # âœ… ë‚ ì§œ ì¶”ê°€
            })

if __name__ == "__main__":
    all_articles = []
    for page in range(1, 6):
        data = crawl_lease_properties(page)
        if data and "articleList" in data:
            all_articles.extend(data["articleList"])
        else:
            print(f"âŒ í˜ì´ì§€ {page}ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    today = datetime.datetime.now().strftime("%Y%m%d")
    filename = os.path.join(DATA_FOLDER, f"ì„¼í…€íŒ°ë¦¬ìŠ¤_ì „ì„¸_{today_date}.csv")

    # âœ… ë°ì´í„°ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ì €ì¥
    if all_articles:
        save_to_csv(all_articles, filename)
        print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
    else:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")